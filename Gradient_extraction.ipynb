{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "50281f3a-4bde-4346-bb27-09a84b8b29fa",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "def compute_cosine_similarity(a, b):\n",
    "    a = np.atleast_2d(a)\n",
    "    b = np.atleast_2d(b)\n",
    "\n",
    "    if a.shape[0] == 1 and b.shape[0] > 1:\n",
    "        a = a.T  # ensure shape is (n, 1) if needed\n",
    "    if b.shape[0] == 1 and a.shape[0] > 1:\n",
    "        b = b.T\n",
    "\n",
    "    return cosine_similarity(a, b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "d2b06773-7458-4b3e-a5e9-de25afd63e4a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Define the folder containing the gradient results\n",
    "gradient_results_folder = \"gradient_results\"\n",
    "\n",
    "# Iterate through all subfolders in the gradient_results folder\n",
    "for subfolder in os.listdir(gradient_results_folder):\n",
    "    subfolder_path = os.path.join(gradient_results_folder, subfolder)\n",
    "    \n",
    "    # Initialize a list to store the summary data\n",
    "    summary_data = []\n",
    "\n",
    "    if os.path.isdir(subfolder_path) and subfolder.startswith(\"results_gradients_\"):\n",
    "        # Extract sample_size, num_classes, and learning_rate from the folder name\n",
    "        _, _, sample_size, num_classes, learning_rate = subfolder.split(\"_\")\n",
    "        \n",
    "        # Initialize dictionaries to store gradients for each parameter and bias/weight\n",
    "        gradients_dict = {}\n",
    "\n",
    "        # Iterate through class folders (0, 1, 2, ..., num_classes-1)\n",
    "        for class_folder in os.listdir(subfolder_path):\n",
    "            class_folder_path = os.path.join(subfolder_path, class_folder)\n",
    "            if os.path.isdir(class_folder_path):\n",
    "                # Iterate through gradient files in the class folder\n",
    "                for gradient_file in os.listdir(class_folder_path):\n",
    "                    if gradient_file.startswith(\"gradients_cycle_\") and gradient_file.endswith(\".npy\"):\n",
    "                        # Extract param_name and bias/weight from the file name\n",
    "                        _, _, cycle, _, param_name_bias_weight = gradient_file.split(\"_\")\n",
    "                        param_name, bias_weight, _ = param_name_bias_weight.rsplit(\".\")\n",
    "                        \n",
    "                        # Load the gradient data\n",
    "                        gradient_path = os.path.join(class_folder_path, gradient_file)\n",
    "                        gradients = np.load(gradient_path)\n",
    "                        \n",
    "                        # Store gradients in the dictionary\n",
    "                        key = (param_name, bias_weight)\n",
    "                        if key not in gradients_dict:\n",
    "                            gradients_dict[key] = []\n",
    "                        gradients_dict[key].append(gradients)\n",
    "                        \n",
    "        # Calculate statistics across all gradients for each parameter and bias/weight\n",
    "        for (param_name, bias_weight), gradients in gradients_dict.items():\n",
    "            gradients = np.array(gradients)\n",
    "            avg = np.mean(gradients, axis=0)\n",
    "            min_val = np.min(gradients, axis=0)\n",
    "            max_val = np.max(gradients, axis=0)\n",
    "            std = np.std(gradients, axis=0)\n",
    "            \n",
    "            # Initialize a list to store the cosine similarity data\n",
    "            cosine_similarity_data = []\n",
    "            \n",
    "            for gradient in gradients:\n",
    "                c_sim = compute_cosine_similarity(gradient, avg)\n",
    "                cosine_similarity_data.append(c_sim)\n",
    "            # Append the data to the summary list\n",
    "            summary_data.append([\n",
    "            sample_size, num_classes, learning_rate, param_name, bias_weight, avg, min_val, max_val, std, cosine_similarity_data\n",
    "            ])\n",
    "            \n",
    "        # Create a DataFrame from the summary data\n",
    "        summary_df = pd.DataFrame(summary_data, columns=[\n",
    "            \"sample_size\", \"num_classes\", \"learning_rate\", \"param_name\", \"bias/weight\", \"avg\", \"min\", \"max\", \"std\", \"cosine_similarity_data\"\n",
    "        ])\n",
    "\n",
    "        # Save the DataFrame to a CSV file with a name involving sample_size, num_classes, and learning_rate\n",
    "        summary_csv_name = f\"gradients_summary_{sample_size}_{num_classes}_{learning_rate}.csv\"\n",
    "        summary_csv_path = os.path.join(gradient_results_folder, summary_csv_name)\n",
    "        summary_df.to_csv(summary_csv_path, index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
